# -*- coding: utf-8 -*-
"""DCGAN_for_Image_Generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uOBijPEJCS1nthBSu6VhssiEgetGOcOj

# DCGAN for Image Generation
"""

!pip install torch torchvision matplotlib

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

# Check if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Transformations for CIFAR-10
transform = transforms.Compose([
    transforms.Resize(32),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

# Load CIFAR-10 dataset
batch_size = 128
train_loader = torch.utils.data.DataLoader(
    torchvision.datasets.CIFAR10(root='.', train=True, transform=transform, download=True),
    batch_size=batch_size, shuffle=True
)

class Generator(nn.Module):
    def __init__(self, z_dim=100, img_channels=3):
        super(Generator, self).__init__()
        self.gen = nn.Sequential(
            nn.ConvTranspose2d(z_dim, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, img_channels, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.gen(x)

class Discriminator(nn.Module):
    def __init__(self, img_channels=3):
        super(Discriminator, self).__init__()
        self.disc = nn.Sequential(
            nn.Conv2d(img_channels, 128, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.disc(x)

z_dim = 100  # Dimension of the noise vector
img_channels = 3

generator = Generator(z_dim=z_dim, img_channels=img_channels).to(device)
discriminator = Discriminator(img_channels=img_channels).to(device)

# Optimizers
lr = 0.0002
beta1 = 0.5  # Recommended value for DCGANs
G_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))
D_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))

# Loss function
criterion = nn.BCELoss()

def train_discriminator(real_images, fake_images):
    D_optimizer.zero_grad()
    # Train on real images
    real_labels = torch.ones(real_images.size(0), 1, device=device)
    real_loss = criterion(discriminator(real_images).view(-1, 1), real_labels)

    # Train on fake images
    fake_labels = torch.zeros(fake_images.size(0), 1, device=device)
    fake_loss = criterion(discriminator(fake_images).view(-1, 1), fake_labels)

    # Backprop and optimize
    D_loss = real_loss + fake_loss
    D_loss.backward()
    D_optimizer.step()
    return D_loss.item()

def train_generator(fake_images):
    G_optimizer.zero_grad()
    labels = torch.ones(fake_images.size(0), 1, device=device)
    G_loss = criterion(discriminator(fake_images).view(-1, 1), labels)
    G_loss.backward()
    G_optimizer.step()
    return G_loss.item()

# Training parameters
epochs = 100
sample_interval = 20  # Save images every 20 epochs
D_losses, G_losses = [], []

for epoch in range(epochs):
    D_loss_epoch, G_loss_epoch = 0, 0
    for real_images, _ in train_loader:
        # Prepare real and fake images
        real_images = real_images.to(device)
        z = torch.randn(batch_size, z_dim, 1, 1, device=device)
        fake_images = generator(z)

        # Train discriminator and generator
        D_loss_epoch += train_discriminator(real_images, fake_images.detach())
        G_loss_epoch += train_generator(fake_images)

    # Calculate average losses for the epoch
    D_losses.append(D_loss_epoch / len(train_loader))
    G_losses.append(G_loss_epoch / len(train_loader))

    print(f"Epoch [{epoch+1}/{epochs}] | D Loss: {D_losses[-1]:.4f} | G Loss: {G_losses[-1]:.4f}")

    # Save generated images at intervals
    if (epoch + 1) % sample_interval == 0:
        with torch.no_grad():
            z = torch.randn(16, z_dim, 1, 1, device=device)
            generated_images = generator(z).cpu()
            grid_img = torchvision.utils.make_grid(generated_images, nrow=4, normalize=True)
            plt.imshow(grid_img.permute(1, 2, 0).numpy())
            plt.title(f"Epoch {epoch+1}")
            plt.show()

plt.figure(figsize=(10, 5))
plt.plot(D_losses, label="Discriminator Loss")
plt.plot(G_losses, label="Generator Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Visualize real CIFAR-10 images
real_images, _ = next(iter(train_loader))
real_images = torchvision.utils.make_grid(real_images[:16], nrow=4, normalize=True)
plt.figure(figsize=(8, 8))
plt.imshow(real_images.permute(1, 2, 0).numpy())
plt.title("Real CIFAR-10 Images")
plt.show()

# Visualize generated images
with torch.no_grad():
    z = torch.randn(16, z_dim, 1, 1, device=device)
    generated_images = generator(z).cpu()
    generated_images = torchvision.utils.make_grid(generated_images, nrow=4, normalize=True)
    plt.figure(figsize=(8, 8))
    plt.imshow(generated_images.permute(1, 2, 0).numpy())
    plt.title("Generated Images")
    plt.show()

